import { TFile, TFolder, normalizePath, RequestUrlParam } from "obsidian";
import SummarPlugin from "./main";
import { SummarDebug, SummarRequestUrl, SummarViewContainer, showSettingsTab, getAvailableFilePath, sanitizeFileName } from "./globals";
import { SummarAI } from "./summarai";
import { get } from "http";

export class AudioHandler extends SummarViewContainer {

	constructor(plugin: SummarPlugin) {
		super(plugin);
	}

	async sendAudioData(files: FileList | File[], givenFolderPath: string = ""): Promise<{ transcriptedText: string, newFilePath: string }> {
		// Only show the audio files that will actually be sent
		const fileArray = Array.from(files);
		const audioFiles = fileArray.filter(file =>
			file.type.startsWith("audio/") ||
			file.name.toLowerCase().endsWith(".mp3") ||
			file.name.toLowerCase().endsWith(".wav") ||
			file.name.toLowerCase().endsWith(".ogg") ||
			file.name.toLowerCase().endsWith(".m4a") ||
			file.name.toLowerCase().endsWith(".webm")
		);
		const fileNames = audioFiles.map(f => (f as any).webkitRelativePath || f.name).join("\n");
		this.initOutputRecord("transcript");

		this.updateOutputText(`Audio files to be sent:\n${fileNames}\n\nConverting audio to text using [${this.plugin.settingsv2.recording.sttModel}] ...`);
		// this.enableNewNote(false, outputKey);

		let audioList = "";
		let transcriptedText = "";

		// Check if the API key is set
		if (!this.plugin.settingsv2.common.openaiApiKey) {
			SummarDebug.Notice(0,
				"API key is missing. Please add your API key in the settings."
			);
			return { transcriptedText: "", newFilePath: "" };
		}

		// Convert FileList to an array
		const fileArray2 = Array.from(files);

		// Sort files by their relative path (webkitRelativePath if available, otherwise file name)
		const sortedFiles = fileArray2.sort((a, b) => {
			const pathA = (a as any).webkitRelativePath || a.name;
			const pathB = (b as any).webkitRelativePath || b.name;
			return pathA.localeCompare(pathB);
		});

		// Calculate the common folder path
		let folderPath = "";
		let noteFilePath = "";
		let originalFolderPath = ""; // ì›ë³¸ í´ë” ê²½ë¡œ ì €ì¥
		
		if (!givenFolderPath || givenFolderPath.length===0) {
			if (sortedFiles.length === 1) {
				folderPath  = sanitizeFileName(sortedFiles[0].name.substring(0,sortedFiles[0].name.lastIndexOf('.')) || sortedFiles[0].name);
				originalFolderPath = folderPath;
				noteFilePath = normalizePath(`${this.plugin.settingsv2.recording.recordingDir}`);
				SummarDebug.log(1, `sendAudioData - only one file`)
			} else {
				folderPath = sanitizeFileName(getCommonFolderPath(sortedFiles));
				originalFolderPath = folderPath;
				SummarDebug.log(1, `sendAudioData - Detected folder path: ${folderPath}`); // Debug log
				noteFilePath = normalizePath(`${this.plugin.settingsv2.recording.recordingDir}/${folderPath}`);
			}
		} else {
			noteFilePath = givenFolderPath;
			const match = givenFolderPath.match(/[^\/]+$/);
			folderPath = match ? sanitizeFileName(match[0]) : sanitizeFileName(noteFilePath);
			originalFolderPath = folderPath;
			SummarDebug.log(1, `sendAudioData - Given folder path: ${folderPath}`); // Debug log
		}

		SummarDebug.log(1, `sendAudioData - noteFilePath: ${noteFilePath}`);
		SummarDebug.log(1, `Number of sorted files: ${sortedFiles.length}`);

		// ì„ì‹œë¡œ íŒŒì¼ë“¤ì„ ì €ì¥í•  ì •ë³´ë¥¼ ìˆ˜ì§‘ (ë‚˜ì¤‘ì— í´ë”ëª… ë³€ê²½ í›„ ì‹¤ì œ ì €ì¥)
		const filesToSave: { file: File; fileName: string; }[] = [];
		
		for (const [index, file] of sortedFiles.entries()) {
			const filePath = (file as any).webkitRelativePath || file.name;
			SummarDebug.log(1, `File ${index + 1}: ${filePath}`);
			if (isAudioFile(file)) {
				filesToSave.push({ file, fileName: file.name });
			}
		}

		this.startTimer()

		// Process files in parallel
		const handler = this;
		// ìµœëŒ€ ë™ì‹œ ìš”ì²­ ê°œìˆ˜
		const MAX_CONCURRENT = 2;

		// Promise poolë¡œ ë™ì‹œ transcription ì œí•œ (stock í˜„ìƒ ì—†ëŠ” ì•ˆì „í•œ íŒ¨í„´)
		async function runWithConcurrencyLimit(tasks: (() => Promise<any>)[], limit: number): Promise<any[]> {
			const results: any[] = [];
			let next = 0;
			let active = 0;
			return new Promise((resolve, reject) => {
				function runNext() {
					if (next >= tasks.length && active === 0) {
						resolve(results);
						return;
					}
					while (active < limit && next < tasks.length) {
						const current = next++;
						active++;
						tasks[current]().then((result) => {
							results[current] = result;
							active--;
							runNext();
						}).catch(reject);
					}
				}
				runNext();
			});
		}

		// transcriptionPromisesë¥¼ í•¨ìˆ˜ ë°°ì—´ë¡œ ë³€ê²½
		const transcriptionTasks = filesToSave.map((fileInfo) => async () => {
			const { file, fileName } = fileInfo;
			const audioFilePath = normalizePath(`${noteFilePath}/${fileName}`);
			SummarDebug.log(1, `audioFilePath: ${audioFilePath}`);
			const match = fileName.match(/_(\d+)s\.(webm|wav|mp3|ogg|m4a)$/); // find
			const seconds = match ? parseInt(match[1], 10) : 0; // convert to seconds

			// ì¬ì‹œë„ ë¡œì§ ë˜í¼
			async function transcribeWithRetry() {
				let lastError = null;
				for (let attempt = 1; attempt <= 3; attempt++) {
					try {
						// if (this.plugin.settings.sttModel === "gemini-2.0-flash") {
						if (this.plugin.settingsv2.recording.sttModel.toLowerCase().includes("gemini")) {
							const { base64, mimeType } = await this.readFileAsBase64(audioFilePath);
							const blob = file.slice(0, file.size, file.type);
							const duration = await getAudioDurationFromBlob(blob, fileName);
							SummarDebug.log(1, `==========\nsendAudioData() - file: ${fileName}, duration: ${duration} seconds`);
							const transcript = await this.callGeminiTranscription(base64, mimeType, duration) || "";
							SummarDebug.log(3, transcript);
							SummarDebug.log(1, 'seconds: ', seconds);
							const strContent = this.adjustSrtTimestamps(transcript, seconds);
							return strContent;
						} else if (this.plugin.settingsv2.recording.sttModel && this.plugin.settingsv2.recording.sttModel.toLowerCase().includes("google")) {
							const ext = fileName.split(".").pop()?.toLowerCase();
							const encoding = this.getEncodingFromExtension(ext);
							const { base64: audioBase64 } = await this.readFileAsBase64(audioFilePath);
							const transcript = await this.callGoogleTranscription(audioBase64, encoding as string);
							return transcript || "";
						} else {
							const blob = file.slice(0, file.size, file.type);
							const { body: finalBody, contentType } = await this.buildMultipartFormData(blob, fileName, file.type);
							const duration = await getAudioDurationFromBlob(blob, fileName);

							SummarDebug.log(1, `==========\nsendAudioData() - file: ${fileName}, duration: ${duration} seconds`);

							const data = await this.callWhisperTranscription(finalBody, contentType, duration);
							// SummarDebug.log(1, `sendAudioData() - 1st response data: ${JSON.stringify(data)}`);							

							// ì‘ë‹µ í™•ì¸
							if (!data.segments || data.segments.length === 0) {
								SummarDebug.log(1, `No transcription segments received for file: ${fileName}`);
								if (data.text && data.text.length > 0) {
									return data.text;
								} else {
									SummarDebug.log(1, `No transcription text received for file: ${fileName}`);
									return "";
								}
							}

							SummarDebug.log(3, data);
							// SRT í¬ë§· ë³€í™˜
							const srtContent = data.segments
								.map((segment: any, index: number) => {
									const start = formatTime(segment.start + seconds);
									const end = formatTime(segment.end + seconds);
									const text = segment.text.trim();

									// return `${index + 1}\n${start} --> ${end}\n${text}\n`;
									return `${start} --> ${end}\n${text}\n`;
								})
								.join("");

							return srtContent;
						}
					} catch (error: any) {
						lastError = error;
						// 503 ì—ëŸ¬ë§Œ ì¬ì‹œë„, ê·¸ ì™¸ëŠ” ë°”ë¡œ break
						if (error && (error.status === 503 || (error.message && error.message.includes("503")))) {
							SummarDebug.error(1, `503 error on attempt ${attempt} for file ${fileName}, retrying...`, error);
							if (attempt < 3) await new Promise(res => setTimeout(res, 1000 * attempt));
							continue;
						} else {
							SummarDebug.error(1, `Error processing file ${fileName}:`, error);
							break;
						}
					}
				}
				SummarDebug.error(1, `Failed to transcribe file ${fileName} after 3 attempts. Last error:`, lastError);
				this.stopTimer();
				return { __isTranscribeError: true, error: lastError };
			}
			// ì‹¤ì œ í˜¸ì¶œ
			return await transcribeWithRetry.call(this);
		});

		// Wait for all transcriptions to complete
		const transcriptions = await runWithConcurrencyLimit(transcriptionTasks, MAX_CONCURRENT);

        // ì‹¤íŒ¨ íŒŒì¼ ì •ë³´ ìˆ˜ì§‘
        const failedFiles: { name: string, error: any }[] = [];
        filesToSave.forEach((fileInfo, idx) => {
            const t = transcriptions[idx];
            const isEmpty = (typeof t === 'string') ? t.trim() === "" : !t;
            if (!t || isEmpty) {
                if (typeof t === 'object' && t !== null && t.__isTranscribeError) {
                    failedFiles.push({ name: fileInfo.fileName, error: t.error });
                } else {
                    failedFiles.push({ name: fileInfo.fileName, error: null });
                }
            }
        });

        if (failedFiles.length > 0) {
			this.stopTimer();

            let errorMsg = '\u274C Failed to transcribe some audio files. All files must be processed successfully to proceed.\n';
            errorMsg += failedFiles.map(f => {
                let errStr = f.error ? (f.error.status ? `[${f.error.status}] ` : '') + (f.error.message || f.error.toString?.() || f.error) : 'Unknown error';
                return `- ${f.name}: ${errStr}`;
            }).join('\n');
            this.updateOutputText(errorMsg);
            throw new Error("One or more audio transcriptions failed. Aborting next steps.");
        }

        // Combine all transcriptions with filename headers
		transcriptedText = filesToSave
			.map((fileInfo, idx) => {
				const header = `----- [${fileInfo.fileName}] ------\n`;
				const t = transcriptions[idx];
				// stringì´ ì•„ë‹ˆë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ëŒ€ì²´
				return header + (typeof t === "string" ? t : "");
			})
			.join("\n");

		// ë¯¸íŒ… ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ê°€ì ¸ì˜¤ê¸° (í´ë”ëª… ë³€ê²½ ê°€ëŠ¥ì„± ë•Œë¬¸ì— baseFilePathëŠ” ë‚˜ì¤‘ì— ê³„ì‚°)
		let meetingInfoContent = "";
		const meetingInfoPath = normalizePath(`${noteFilePath}/${folderPath} meeting-info.md`);
		SummarDebug.log(1, `Checking for meeting info at: ${meetingInfoPath}`);
		SummarDebug.log(1, `Calendar handler available: ${!!this.plugin.calendarHandler}`);
		SummarDebug.log(1, `Audio files count: ${filesToSave.length}`);
		
		try {
			const meetingInfoExists = await this.plugin.app.vault.adapter.exists(meetingInfoPath);
			if (meetingInfoExists) {
				meetingInfoContent = await this.plugin.app.vault.adapter.read(meetingInfoPath);
				SummarDebug.log(1, `Meeting info found and loaded from: ${meetingInfoPath}`);
				
				// ê¸°ì¡´ meeting-infoê°€ ìˆì–´ë„ ë‹¤ì¤‘ íŒŒì¼ì˜ ê²½ìš° í´ë”ëª…ì´ ìº˜ë¦°ë” ê¸°ë°˜ìœ¼ë¡œ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
				if (filesToSave.length > 1) {
					const audioFiles = filesToSave.map(f => f.file);
					
					// ë¨¼ì € ì €ì¥ëœ ì´ë²¤íŠ¸ ë©”íƒ€ë°ì´í„°ë¥¼ í™•ì¸
					let event = await this.loadEventMetadata(originalFolderPath);
					
					// ë©”íƒ€ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë²¤íŠ¸ ì°¾ê¸°
					if (!event) {
						event = await this.plugin.calendarHandler?.findEventFromAudioFiles(audioFiles);
					}
					
					if (event) {
						const safeMeetingTitle = event.safeMeetingTitle || sanitizeFileName(event.title);
						// í´ë”ëª…ì— ë¯¸íŒ… ì œëª©ì´ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ í´ë”ëª… ì—…ë°ì´íŠ¸
						if (!originalFolderPath.includes(safeMeetingTitle)) {
							SummarDebug.log(1, `Updating folder for existing meeting-info with calendar event: ${event.title}`);
							const { updatedNoteFilePath, updatedFolderPath } = await this.updateFolderWithMeetingTitle(
								meetingInfoContent,
								audioFiles,
								originalFolderPath,
								noteFilePath,
								folderPath,
								givenFolderPath
							);
							noteFilePath = updatedNoteFilePath;
							folderPath = updatedFolderPath;
						}
					}
				}
			} else {
				SummarDebug.log(1, `No existing meeting-info.md found, attempting to generate from audio files`);
				
				// ìº˜ë¦°ë” ì´ë²¤íŠ¸ì—ì„œ ë¯¸íŒ… ì •ë³´ ì°¾ê¸°
				const audioFiles = filesToSave.map(f => f.file);
				meetingInfoContent = await this.findMeetingInfoFromAudioFiles(audioFiles);
				
				if (meetingInfoContent) {
					// ë‹¤ì¤‘ íŒŒì¼ì˜ ê²½ìš° í´ë”ëª… ì—…ë°ì´íŠ¸
					if (filesToSave.length > 1) {
						const { updatedNoteFilePath, updatedFolderPath } = await this.updateFolderWithMeetingTitle(
							meetingInfoContent,
							audioFiles,
							originalFolderPath,
							noteFilePath,
							folderPath,
							givenFolderPath
						);
						noteFilePath = updatedNoteFilePath;
						folderPath = updatedFolderPath;
					}
					
					// ë¯¸íŒ… ì •ë³´ ì €ì¥
					await this.saveMeetingInfo(meetingInfoContent, noteFilePath, folderPath);
				}
			}
		} catch (error) {
			SummarDebug.log(1, `Error loading meeting info from: ${meetingInfoPath}`, error);
		}

		// í´ë”ëª… ë³€ê²½ì´ ì™„ë£Œëœ í›„ ì‹¤ì œ íŒŒì¼ë“¤ ì €ì¥ ë° audioList ìƒì„±
		await this.plugin.app.vault.adapter.mkdir(noteFilePath);
		for (const fileInfo of filesToSave) {
			const audioFilePath = normalizePath(`${noteFilePath}/${fileInfo.fileName}`);
			SummarDebug.log(1, `audioFilePath: ${audioFilePath}`);

			// Check if the file already exists
			const fileExists = await this.plugin.app.vault.adapter.exists(audioFilePath);
			if (!fileExists) {
				const fileContent = await fileInfo.file.arrayBuffer();

				try {
					await this.plugin.app.vault.adapter.writeBinary(audioFilePath, fileContent);
					SummarDebug.log(1, `File saved at: ${audioFilePath}`);
				} catch (error) {
					SummarDebug.error(1, `Error saving file: ${audioFilePath}`, error);
				}
			} else {
				SummarDebug.log(1, `File already exists: ${audioFilePath}`);
			}

			audioList += `![[${audioFilePath}]]\n`;
			SummarDebug.log(1, `audioList: ${audioList}`);
		}

		// í´ë”ëª… ë³€ê²½ì´ ì™„ë£Œëœ í›„ baseFilePath ê³„ì‚°
		const baseFilePath = normalizePath(`${noteFilePath}/${folderPath}`);

		const existingFile = this.plugin.app.vault.getAbstractFileByPath(`${baseFilePath} transcript.md`);
		let newFilePath = "";
		if (existingFile && existingFile instanceof TFile) {
			// If the file exists, find a new unique filename
			newFilePath = getAvailableFilePath(baseFilePath, " transcript.md", this.plugin);
			SummarDebug.log(1, `File already exists. Created new file: ${newFilePath}`);
		} else {
			// If the file does not exist, create it
			newFilePath = `${baseFilePath} transcript.md`;
			SummarDebug.log(1, `File created: ${newFilePath}`);
		}

		// ë¯¸íŒ… ì •ë³´ë¥¼ í¬í•¨í•œ transcription ë‚´ìš© ìƒì„±
		let transcriptionContent = "";
		if (meetingInfoContent) {
			transcriptionContent = `${meetingInfoContent}\n\n---\n\n## ğŸµ Audio Files\n${audioList}\n## ğŸ“ Transcription\n${transcriptedText}`;
		} else {
			// ë¯¸íŒ… ì •ë³´ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ì•ˆë‚´ ë©”ì‹œì§€ ì¶”ê°€
			const noMeetingInfo = `## ğŸ“‹ Meeting Information\n\nâš ï¸ **No calendar event found for this recording time**\n\nThis transcription was created without associated calendar information. You can manually add meeting details if needed.\n\n---\n\n`;
			transcriptionContent = `${noMeetingInfo}## ğŸµ Audio Files\n${audioList}\n## ğŸ“ Transcription\n${transcriptedText}`;
		}

		await this.plugin.app.vault.create(newFilePath, transcriptionContent);
		this.updateOutputText(transcriptionContent);

		this.enableNewNote(true, newFilePath);
		
		// summaryê°€ í™œì„±í™”ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ transcript íŒŒì¼ì„ ì—´ê¸°
		// summaryê°€ í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ë‚˜ì¤‘ì— summaryë‚˜ refined íŒŒì¼ì´ ì—´ë¦´ ì˜ˆì •ì´ë¯€ë¡œ transcriptëŠ” ì—´ì§€ ì•ŠìŒ
		if (!this.plugin.settingsv2.recording.saveTranscriptAndRefineToNewNote) {
			await this.plugin.app.workspace.openLinkText(
				normalizePath(newFilePath),
				"",
				true
			);
		}
		this.foldOutput(true);
		
		// Daily Notesì— ì „ì‚¬ ì™„ë£Œ ë§í¬ ì¶”ê°€ (ë…¹ìŒ ë‚ ì§œ ê¸°ì¤€)
		const recordingDate = this.extractRecordingDateFromPath(folderPath, filesToSave, noteFilePath);
		await this.plugin.dailyNotesHandler.addMeetingLinkToDailyNote(newFilePath, 'transcript', recordingDate);
		
		this.stopTimer();
		return {transcriptedText, newFilePath};

		function formatTime(seconds: number): string {
			const hours = Math.floor(seconds / 3600).toString().padStart(2, "0");
			const minutes = Math.floor((seconds % 3600) / 60).toString().padStart(2, "0");
			const secs = Math.floor(seconds % 60).toString().padStart(2, "0");
			const milliseconds = Math.floor((seconds % 1) * 1000).toString().padStart(3, "0");
	
			return `${hours}:${minutes}:${secs}.${milliseconds}`;
		}

		// Helper function to calculate the common folder path
		function getCommonFolderPath(files: File[]): string {
			// Extract full paths (webkitRelativePath includes folder structure)
			const paths = files.map((file) => (file as any).webkitRelativePath || file.name);

			if (paths.length === 0) {
				return ""; // No files provided
			}

			// Split paths into components and find the common prefix
			const splitPaths = paths.map((path) => path.split("/"));
			const commonParts: string[] = [];

			for (let i = 0; i < splitPaths[0].length; i++) {
				const part = splitPaths[0][i];
				if (splitPaths.every((segments) => segments[i] === part)) {
					commonParts.push(part);
				} else {
					break;
				}
			}
			return commonParts.join("/");
		}

		function getEncodingFromExtension(ext?: string): string | null {
			switch (ext) {
			  case "webm": return "WEBM_OPUS";
			  case "mp3": return "MP3";
			  case "wav": return "LINEAR16";
			  case "ogg": return "OGG_OPUS";
			  case "m4a": return "MP4";
			  default: return null;
			}
		}

	}


	// Check if the file is an audio or webm file
	isAudioOrWebmFile(file: TFile): boolean {
		const audioExtensions = ["mp3", "wav", "flac", "m4a", "ogg", "webm"];
		const extension = file.extension?.toLowerCase();
		return audioExtensions.includes(extension);
	}

	// Check if the folder contains any audio or webm files
	folderContainsAudioOrWebm(folder: TFolder): boolean {
		const files = this.plugin.app.vault.getFiles();
		return files.some(
			(file) =>
				file.parent !== null && // Ensure file.parent is not null
				file.parent.path === folder.path &&
				this.isAudioOrWebmFile(file)
		);
	}

	mapLanguageToWhisperCode(lang: string): string {
		const map: Record<string, string> = {
		  // BCP-47 ì „ì²´ ì½”ë“œ â†’ Whisper ì–¸ì–´ ì½”ë“œ
		  "ko-KR": "ko",
		  "ja-JP": "ja",
		  "en-US": "en",
		  "en-GB": "en",
		  "zh-CN": "zh",
		  "zh-TW": "zh",
		  "fr-FR": "fr",
		  "de-DE": "de",
		  "es-ES": "es",
		  "pt-PT": "pt",
		  "pt-BR": "pt",
		  "vi-VN": "vi", 
		  "th-TH": "th", 
		  
		  "ko": "ko",
		  "ja": "ja",
		  "en": "en",
		  "zh": "zh",
		  "fr": "fr",
		  "de": "de",
		  "es": "es",
		  "pt": "pt",
		  "vi": "vi",
		  "th": "th",
		};
	  
		const normalized = lang.trim().toLowerCase();
		return map[normalized] ?? "ko"; 
	}

	async buildMultipartFormData(blob: Blob, fileName: string, fileType: string): Promise<{ body: Blob, contentType: string }> {
		const encoder = new TextEncoder();
		const boundary = "----SummarFormBoundary" + Math.random().toString(16).slice(2);
		const CRLF = "\r\n";

		const bodyParts: BlobPart[] = [];

		function addField(name: string, value: string) {
			bodyParts.push(
				encoder.encode(`--${boundary}${CRLF}`),
				encoder.encode(`Content-Disposition: form-data; name="${name}"${CRLF}${CRLF}`),
				encoder.encode(`${value}${CRLF}`)
			);
		}

		function addFileField(name: string, filename: string, type: string, content: ArrayBuffer) {
			bodyParts.push(
				encoder.encode(`--${boundary}${CRLF}`),
				encoder.encode(`Content-Disposition: form-data; name="${name}"; filename="${filename}"${CRLF}`),
				encoder.encode(`Content-Type: ${type}${CRLF}${CRLF}`),
				content,
				encoder.encode(CRLF)
			);
		}

		const arrayBuffer = await blob.arrayBuffer();

		addFileField("file", fileName, fileType, arrayBuffer);
		// addField("model", this.plugin.settings.sttModel || "whisper-1");
		addField("model", this.plugin.settingsv2.recording.sttModel || this.plugin.getDefaultModel("sttModel"));

		if (this.plugin.settingsv2.recording.recordingLanguage) {
			addField("language", this.mapLanguageToWhisperCode(this.plugin.settingsv2.recording.recordingLanguage));
		}

		addField("response_format", this.plugin.settingsv2.recording.sttModel === "whisper-1" ? "verbose_json" : "json");

		if ((this.plugin.settingsv2.recording.sttModel === "gpt-4o-mini-transcribe" || this.plugin.settingsv2.recording.sttModel === "gpt-4o-transcribe")
			&& this.plugin.settingsv2.recording.sttPrompt[this.plugin.settingsv2.recording.sttModel]) {
			addField("prompt", this.plugin.settingsv2.recording.sttPrompt[this.plugin.settingsv2.recording.sttModel]);
			this.pushOutputPrompt(this.plugin.settingsv2.recording.sttPrompt[this.plugin.settingsv2.recording.sttModel]);
		} else {
			this.pushOutputPrompt('transcribe using whisper-1');
		}

		bodyParts.push(encoder.encode(`--${boundary}--${CRLF}`));

		return {
			body: new Blob(bodyParts, { type: `multipart/form-data; boundary=${boundary}` }),
			contentType: `multipart/form-data; boundary=${boundary}`
		};
	}

	async callWhisperTranscription(requestbody: Blob, contentType: string, duration: number): Promise<any> {
		const sttModel = this.plugin.settingsv2.recording.sttModel;
		const summarai = new SummarAI(this.plugin, sttModel, 'stt');
		if (!summarai.hasKey(true, this.outputRecord.key, this.outputRecord.label as string)) return '';			

		
		const json = await summarai.audioTranscription((await requestbody.arrayBuffer() as ArrayBuffer), contentType, duration);
		return json;
    }

	////////////////////////////
	async readFileAsBase64(filePath: string): Promise<{ base64:string; mimeType: string }> {
		const arrayBuffer = await this.plugin.app.vault.adapter.readBinary(filePath);
		const uint8Array = new Uint8Array(arrayBuffer);
		const mimeType = detectMimeType(uint8Array);

		let binary = '';
		uint8Array.forEach(byte => binary += String.fromCharCode(byte));
		return { base64: btoa(binary), mimeType };

		function detectMimeType(data: Uint8Array): string {
			// MIME type signatures for common audio formats
			const signatures: { [key: string]: string } = {
				'4944330': 'audio/mpeg',              // MP3 - ID3v2
				'fff': 'audio/mpeg',                 // MP3 - No ID3 or ID3v1
				'52494646': 'audio/wav',             // WAV - RIFF
				'4f676753': 'audio/ogg',             // OGG
				'667479704d3441': 'audio/m4a',       // M4A
				'1a45dfa3': 'audio/webm'            // WEBM
			};
			
			// convert first 12 bytes to hex
			let hex = '';
			for (let i = 0; i < Math.min(12, data.length); i++) {
				let h = data[i].toString(16);
				hex += h.length === 1 ? '0' + h : h;
			}
			
			// match signature
			for (const [signature, mime] of Object.entries(signatures)) {
				if (hex.startsWith(signature)) {
					return mime;
				}
			}
			
			// default MIME type
			return 'application/octet-stream';
		}
	}

	GoogleApiKeyAlert() {
		const fragment = document.createDocumentFragment();
		// const message1 = document.createElement("span");
		// message1.textContent = "To publish your notes to Confluence, " +
		// 	"please specify the Parent Page where the content will be saved. \n";
		// fragment.appendChild(message1);

		// ë§í¬ ìƒì„± ë° ìŠ¤íƒ€ì¼ë§
		const link = document.createElement("a");
		link.textContent = "Google API key is missing. Please add your API key in the settings.";
		link.href = "#";
		link.style.cursor = "pointer";
		link.style.color = "var(--text-accent)"; // ë§í¬ ìƒ‰ìƒ ì„¤ì • (ì˜µì…˜)
		link.addEventListener("click", (event) => {
			event.preventDefault(); // ê¸°ë³¸ ë™ì‘ ë°©ì§€
			showSettingsTab(this.plugin, 'common-tab');
		});
		fragment.appendChild(link);
		SummarDebug.Notice(0, fragment, 0);
		
		// SummarDebug.Notice(0, "Please set Confluence Parent Page URL, Space Key, and ID in the settings.",0);
		return;	
	}

	async callGoogleTranscription(audioBase64: string, encoding: string): Promise<string | null> {
		const apiKey = this.plugin.settingsv2.common.googleApiKey;
		if (!apiKey || apiKey.length === 0) {
		  SummarDebug.Notice(1, "Google API key is missing. Please add your API key in the settings.");
		  this.GoogleApiKeyAlert();
		  return null;
		}
	
		const request: RequestUrlParam = {	
		  url: `https://speech.googleapis.com/v1/speech:recognize?key=${this.plugin.settingsv2.common.googleApiKey}`,
		  method: "POST",
		  headers: {
			"Content-Type": "application/json",
		  },
		  body: JSON.stringify({
			config: {
			  encoding: encoding,
			//   sampleRateHertz: 16000,
			  languageCode: "ko-KR",
			},
			audio: {
			  content: audioBase64,
			},
		  }),
		};
	
		try {
		  const response = await SummarRequestUrl(this.plugin, request);
		  const results = response.json.results;
		  if (results && results.length > 0) {
			SummarDebug.log(1, `Google Speech-to-Text API response: ${JSON.stringify(results)}`);
			return results.map((r: any) => r.alternatives[0].transcript).join("\n");
		  } else {
			const errorMessage = response.json.error?.message || "Unknown error";
			if (errorMessage) {
				SummarDebug.Notice(1, `Google Speech-to-Text API error: ${errorMessage}`);
				throw new Error(`Google Speech-to-Text API error: ${errorMessage}`);
			} else {
				SummarDebug.Notice(1, "No transcription results found.");	
			}
			return "";
		  }
		} catch (error) {
		  SummarDebug.Notice(1, "Error calling Google Speech-to-Text API:", error);
		  return null;
		}
	}
	
	async callGeminiTranscription(base64: string, mimeType: string, duration: number): Promise<string | null> {
		const sttModel = this.plugin.settingsv2.recording.sttModel;
		const summarai = new SummarAI(this.plugin, sttModel, 'stt');
		if (!summarai.hasKey(true, this.outputRecord.key, this.outputRecord.label as string)) return '';			

		// sttModelì— ë”°ë¼ ì ì ˆí•œ prompt ì„ íƒ
		let systemInstruction = "";
		if (this.plugin.settingsv2.recording.sttPrompt[sttModel]) {
			systemInstruction = this.plugin.settingsv2.recording.sttPrompt[sttModel];
		} else {
			// fallback to default instruction
			systemInstruction = `You are an expert in audio-to-text transcription.\n\n1. Accurately transcribe the provided audio content into text.\n2. You MUST output the transcription in SRT (SubRip Text) format only.\n3. Split each subtitle entry into segments of 2-3 seconds.\n4. Follow this strict SRT format for every output:\n   - ommit Sequential number\n   - Start time --> End time (in 00:00:00.000 --> 00:00:00.000 format)\n   - Text content\n   - Blank line (to separate from next entry)\n\n5. Include appropriate punctuation and paragraphing according to the language's grammar and context.\n6. Indicate non-verbal sounds, music, or sound effects in brackets, such as [noise], [music], [applause], etc.\n7. If multiple speakers are present, clearly indicate speaker changes (e.g., "Speaker 1: Hello").\n\nYour response must contain ONLY the SRT format transcript with no additional explanation or text.`;
		}
		
		if (this.plugin.settingsv2.recording.recordingLanguage) {
			systemInstruction += ` The input language is ${this.mapLanguageToWhisperCode(this.plugin.settingsv2.recording.recordingLanguage)}.`;
		}

		this.pushOutputPrompt(systemInstruction);

		try {
			const bodyContent = JSON.stringify({
				contents: [{
					parts: [
						{ text: systemInstruction },
						{
							inlineData: {
								mimeType: mimeType,
								data: base64
							}
						}
					]
				}],
			});

			await summarai.completeWithBody(bodyContent, duration);
			const status = summarai.response.status;
			const result = summarai.response.text;


			if (status !== 200) {
				throw new Error(`API ì˜¤ë¥˜ (${status}): ${result}`);
			}

			if (result && result.length > 0) {
				if (typeof result === 'string') {
					return result;
				} else {
					throw new Error('Gemini API returned non-string result');
				}
			} else {
				throw new Error('candidates not found in the response');
			}
		} catch (error) {
			SummarDebug.error(1, "Error calling Gemini API:", error);
			throw new Error(`Error calling gemini api: ${error.message}`);
		}
	}



	adjustSrtTimestamps(srtContent: string, secondsToAdd: number): string {
		// timestamp format: 00:00:00,000 --> 00:00:00,000
		const timestampRegex = /(\d{2}):(\d{2}):(\d{2}).(\d{3}) --> (\d{2}):(\d{2}):(\d{2}).(\d{3})/g;
		
	    let adjustedContent = srtContent.replace(
			/(\d{2}):(\d{2}):(\d{2})\.(\d{3}) --> (\d{2}):(\d{2}):(\d{2})\.(\d{3})/g, 
			(match, startHour, startMin, startSec, startMs, endHour, endMin, endSec, endMs) => {
				// ì‹œì‘ ì‹œê°„ì— ì´ˆ ì¶”ê°€
				const startTime = new Date(0);
				startTime.setHours(parseInt(startHour, 10));
				startTime.setMinutes(parseInt(startMin, 10));
				startTime.setSeconds(parseInt(startSec, 10) + secondsToAdd); // ì´ˆ ì¶”ê°€
				startTime.setMilliseconds(parseInt(startMs, 10));
				
				// ì¢…ë£Œ ì‹œê°„ì— ì´ˆ ì¶”ê°€
				const endTime = new Date(0);
				endTime.setHours(parseInt(endHour, 10));
				endTime.setMinutes(parseInt(endMin, 10));
				endTime.setSeconds(parseInt(endSec, 10) + secondsToAdd); // ì´ˆ ì¶”ê°€
				endTime.setMilliseconds(parseInt(endMs, 10));
				
				// ìƒˆ íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì›ë˜ í˜•ì‹ê³¼ ë™ì¼í•˜ê²Œ HH:MM:SS.mmm)
				const newStartTime = `${padZero(startTime.getHours())}:${padZero(startTime.getMinutes())}:${padZero(startTime.getSeconds())}.${padZeroMs(startTime.getMilliseconds())}`;
				const newEndTime = `${padZero(endTime.getHours())}:${padZero(endTime.getMinutes())}:${padZero(endTime.getSeconds())}.${padZeroMs(endTime.getMilliseconds())}`;
				
				return `${newStartTime} --> ${newEndTime}`;
			}
		);
		adjustedContent = adjustedContent.replace(
			/(\d{2}):(\d{2})\.(\d{3}) --> (\d{2}):(\d{2})\.(\d{3})/g,
			(match, startMin, startSec, startMs, endMin, endSec, endMs) => {
				// ì‹œì‘ ì‹œê°„ì— ì´ˆ ì¶”ê°€
				const startTime = new Date(0);
				startTime.setHours(0); // ì‹œê°„ì€ 0ìœ¼ë¡œ ì„¤ì •
				startTime.setMinutes(parseInt(startMin, 10));
				startTime.setSeconds(parseInt(startSec, 10) + secondsToAdd); // ì´ˆ ì¶”ê°€
				startTime.setMilliseconds(parseInt(startMs, 10));
				
				// ì¢…ë£Œ ì‹œê°„ì— ì´ˆ ì¶”ê°€
				const endTime = new Date(0);
				endTime.setHours(0); // ì‹œê°„ì€ 0ìœ¼ë¡œ ì„¤ì •
				endTime.setMinutes(parseInt(endMin, 10));
				endTime.setSeconds(parseInt(endSec, 10) + secondsToAdd); // ì´ˆ ì¶”ê°€
				endTime.setMilliseconds(parseInt(endMs, 10));
				
				// ì‹œê°„ ê°’ì— ë”°ë¼ ì¶œë ¥ í˜•ì‹ ê²°ì •
				// 60ë¶„ ì´ìƒìœ¼ë¡œ ë³€ê²½ëœ ê²½ìš° HH:MM:SS.mmm í˜•ì‹ìœ¼ë¡œ ë³€í™˜
				const newStartTime = `${padZero(startTime.getHours())}:${padZero(startTime.getMinutes())}:${padZero(startTime.getSeconds())}.${padZeroMs(startTime.getMilliseconds())}`;
				const newEndTime = `${padZero(endTime.getHours())}:${padZero(endTime.getMinutes())}:${padZero(endTime.getSeconds())}.${padZeroMs(endTime.getMilliseconds())}`;

				return `${newStartTime} --> ${newEndTime}`;
			}
		);
		return adjustedContent;
		
		/**
		 * Fill hours, minutes, and seconds with a two-digit string (e.g. 5 -> "05")
		 */
		function padZero(num: number): string {
			return num.toString().padStart(2, '0');
		}
		
		/**
		 * Fill milliseconds with a three-digit string (e.g. 5 -> "005")
		 */
		function padZeroMs(num: number): string {
			return num.toString().padStart(3, '0');
		}

	}

	/**
	 * ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ë¡œë¶€í„° ìº˜ë¦°ë” ì´ë²¤íŠ¸ë¥¼ ì°¾ê³  ë¯¸íŒ… ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
	 */
	private async findMeetingInfoFromAudioFiles(audioFiles: File[]): Promise<string> {
		if (!this.plugin.calendarHandler || audioFiles.length === 0) {
			return "";
		}

		SummarDebug.log(1, `Searching calendar events for ${audioFiles.length} audio files`);
		SummarDebug.log(1, `Audio file names: ${audioFiles.map(f => f.name).join(', ')}`);
		
		// ë¨¼ì € ì²« ë²ˆì§¸ íŒŒì¼ì˜ í´ë”ì—ì„œ ì €ì¥ëœ ì´ë²¤íŠ¸ ë©”íƒ€ë°ì´í„°ë¥¼ í™•ì¸
		const firstFile = audioFiles[0];
		const firstFilePath = firstFile.name;
		const folderPath = firstFilePath.substring(0, firstFilePath.lastIndexOf('/'));
		
		let event = await this.loadEventMetadata(folderPath);
		
		// ë©”íƒ€ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë²¤íŠ¸ ì°¾ê¸°
		if (!event) {
			event = await this.plugin.calendarHandler.findEventFromAudioFiles(audioFiles);
		}
		
		if (event) {
			SummarDebug.log(1, `Calendar event found: ${event.title}`);
			return this.plugin.calendarHandler.formatEventInfo(event);
		} else {
			SummarDebug.log(1, `No calendar event found for audio files`);
			return "";
		}
	}

	/**
	 * ì €ì¥ëœ ì´ë²¤íŠ¸ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
	 */
	private async loadEventMetadata(folderPath: string): Promise<any> {
		try {
			const metadataPath = normalizePath(folderPath + '/event-metadata.json');
			const file = this.plugin.app.vault.getAbstractFileByPath(metadataPath);
			if (file) {
				const content = await this.plugin.app.vault.read(file as any);
				const metadata = JSON.parse(content);
				SummarDebug.log(1, `Loaded event metadata from: ${metadataPath}`);
				return metadata;
			}
		} catch (error) {
			SummarDebug.log(2, `Failed to load event metadata from: ${folderPath}`, error);
		}
		return null;
	}

	/**
	 * ë‹¤ì¤‘ íŒŒì¼ì˜ ê²½ìš° ìº˜ë¦°ë” ì´ë²¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í´ë”ëª…ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
	 */
	private async updateFolderWithMeetingTitle(
		meetingInfo: string,
		audioFiles: File[],
		originalFolderPath: string,
		noteFilePath: string,
		folderPath: string,
		givenFolderPath: string
	): Promise<{ updatedNoteFilePath: string; updatedFolderPath: string }> {
		
		if (!meetingInfo || audioFiles.length <= 1) {
			return { updatedNoteFilePath: noteFilePath, updatedFolderPath: folderPath };
		}

		// ë¨¼ì € ì €ì¥ëœ ì´ë²¤íŠ¸ ë©”íƒ€ë°ì´í„°ë¥¼ í™•ì¸
		let event = await this.loadEventMetadata(originalFolderPath);
		
		// ë©”íƒ€ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë²¤íŠ¸ ì°¾ê¸°
		if (!event) {
			event = await this.plugin.calendarHandler?.findEventFromAudioFiles(audioFiles);
		}
		
		if (!event) {
			return { updatedNoteFilePath: noteFilePath, updatedFolderPath: folderPath };
		}

		// ë©”íƒ€ë°ì´í„°ì— ì €ì¥ëœ safeMeetingTitleì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í˜„ì¬ ì œëª©ìœ¼ë¡œ ìƒì„±
		const safeMeetingTitle = event.safeMeetingTitle || sanitizeFileName(event.title);
		
		// ë¯¸íŒ… ì œëª©ì´ í´ë”ëª…ì— í¬í•¨ë˜ì–´ ìˆì§€ ì•Šìœ¼ë©´ í´ë”ëª…ì„ ì—…ë°ì´íŠ¸
		if (originalFolderPath.includes(safeMeetingTitle)) {
			SummarDebug.log(1, `Folder already contains meeting title: ${safeMeetingTitle}`);
			return { updatedNoteFilePath: noteFilePath, updatedFolderPath: folderPath };
		}

		// ê¸°ì¡´ í´ë”ëª…ì—ì„œ ë¯¸íŒ… ì œëª© ë¶€ë¶„ì„ ì œê±°í•˜ê³  ìƒˆë¡œìš´ ë¯¸íŒ… ì œëª©ìœ¼ë¡œ êµì²´
		// íŒ¨í„´: YYMMDD-HHMMSS_ê¸°ì¡´ë¯¸íŒ…ì œëª© -> YYMMDD-HHMMSS_ìƒˆë¯¸íŒ…ì œëª©
		const timestampPattern = /^(\d{6}-\d{6})/;
		const timestampMatch = originalFolderPath.match(timestampPattern);
		
		let newFolderPath: string;
		if (timestampMatch) {
			// íƒ€ì„ìŠ¤íƒ¬í”„ ë¶€ë¶„ë§Œ ìœ ì§€í•˜ê³  ìƒˆë¡œìš´ ë¯¸íŒ… ì œëª© ì¶”ê°€
			const timestamp = timestampMatch[1];
			newFolderPath = `${timestamp}_${safeMeetingTitle}`;
			SummarDebug.log(1, `Replacing folder name: ${originalFolderPath} -> ${newFolderPath} (preserving timestamp: ${timestamp})`);
		} else {
			// íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
			newFolderPath = `${originalFolderPath}_${safeMeetingTitle}`;
			SummarDebug.log(1, `Appending to folder name: ${originalFolderPath} -> ${newFolderPath}`);
		}
		
		let newNoteFilePath = "";
		
		if (!givenFolderPath || givenFolderPath.length === 0) {
			newNoteFilePath = normalizePath(`${this.plugin.settingsv2.recording.recordingDir}/${newFolderPath}`);
		} else {
			newNoteFilePath = givenFolderPath.replace(originalFolderPath, newFolderPath);
		}
		
		SummarDebug.log(1, `Updating folder path from '${folderPath}' to '${newFolderPath}' based on calendar event`);

		// í´ë” ì´ë¦„ ë³€ê²½ ë° íŒŒì¼ ì´ë™
		await this.moveFolderAndFiles(noteFilePath, newNoteFilePath);
		
		return { updatedNoteFilePath: newNoteFilePath, updatedFolderPath: newFolderPath };
	}

	/**
	 * ê¸°ì¡´ í´ë”ì˜ íŒŒì¼ë“¤ì„ ìƒˆ í´ë”ë¡œ ì´ë™í•©ë‹ˆë‹¤.
	 */
	private async moveFolderAndFiles(oldPath: string, newPath: string): Promise<void> {
		try {
			// ê¸°ì¡´ í´ë”ê°€ ì¡´ì¬í•˜ë©´ ìƒˆ í´ë”ë¡œ ì´ë¦„ ë³€ê²½
			if (await this.plugin.app.vault.adapter.exists(oldPath)) {
				// ìƒˆ í´ë” ìƒì„±
				await this.plugin.app.vault.adapter.mkdir(newPath);
				
				// ê¸°ì¡´ íŒŒì¼ë“¤ì„ ìƒˆ í´ë”ë¡œ ì´ë™
				const existingFiles = await this.plugin.app.vault.adapter.list(oldPath);
				const movePromises: Promise<void>[] = [];
				
				for (const filePath of existingFiles.files) {
					const fileName = filePath.split('/').pop();
					if (fileName) {
						const oldFilePath = filePath;
						const newFilePath = normalizePath(`${newPath}/${fileName}`);
						
						// ì•ˆì „í•œ íŒŒì¼ ì´ë™: ë³µì‚¬ ì„±ê³µ í™•ì¸ í›„ ì‚­ì œ
						movePromises.push(
							(async () => {
								try {
									const fileContent = await this.plugin.app.vault.adapter.readBinary(oldFilePath);
									await this.plugin.app.vault.adapter.writeBinary(newFilePath, fileContent);
									
									// ë³µì‚¬ê°€ ì„±ê³µí–ˆëŠ”ì§€ í™•ì¸
									const copyExists = await this.plugin.app.vault.adapter.exists(newFilePath);
									if (copyExists) {
										await this.plugin.app.vault.adapter.remove(oldFilePath);
										SummarDebug.log(1, `Moved file from ${oldFilePath} to ${newFilePath}`);
									} else {
										SummarDebug.error(1, `Failed to copy file to ${newFilePath}, keeping original`);
									}
								} catch (error) {
									SummarDebug.error(1, `Error moving file ${oldFilePath}:`, error);
								}
							})()
						);
					}
				}
				
				// ëª¨ë“  íŒŒì¼ ì´ë™ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
				await Promise.all(movePromises);
				
				// ê¸°ì¡´ í´ë”ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì‚­ì œ
				const remainingFiles = await this.plugin.app.vault.adapter.list(oldPath);
				if (remainingFiles.files.length === 0 && remainingFiles.folders.length === 0) {
					await this.plugin.app.vault.adapter.rmdir(oldPath, false);
					SummarDebug.log(1, `Removed empty folder: ${oldPath}`);
				}
			}
		} catch (error) {
			SummarDebug.log(1, `Failed to move folder: ${error}`);
		}
	}

	/**
	 * ë¯¸íŒ… ì •ë³´ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
	 */
	private async saveMeetingInfo(meetingInfo: string, noteFilePath: string, folderPath: string): Promise<void> {
		if (!meetingInfo) return;

		const meetingInfoPath = normalizePath(`${noteFilePath}/${folderPath} meeting-info.md`);
		try {
			await this.plugin.app.vault.adapter.mkdir(noteFilePath);
			await this.plugin.app.vault.adapter.write(meetingInfoPath, meetingInfo);
			SummarDebug.log(1, `Meeting info saved to: ${meetingInfoPath}`);
		} catch (error) {
			SummarDebug.log(1, `Failed to save meeting info: ${error}`);
		}
	}

	/**
	 * í´ë” ê²½ë¡œë‚˜ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤ì—ì„œ ë…¹ìŒ ë‚ ì§œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
	 */
	private extractRecordingDateFromPath(folderPath: string, filesToSave: { file: File; fileName: string; }[], noteFilePath?: string): Date | undefined {
		try {
			SummarDebug.log(2, `Extracting recording date from folderPath: ${folderPath}, noteFilePath: ${noteFilePath || 'N/A'}`);
			
			// 0. ì „ì²´ íŒŒì¼ ê²½ë¡œ(noteFilePath)ì—ì„œ ë¨¼ì € ë‚ ì§œ ì¶”ì¶œ ì‹œë„
			if (noteFilePath) {
				const fullPathDateMatch = noteFilePath.match(/(\d{4})-(\d{2})-(\d{2})|(\d{4})(\d{2})(\d{2})|(\d{4})\.(\d{2})\.(\d{2})|(\d{2})(\d{2})(\d{2})/);
				if (fullPathDateMatch) {
					const date = this.parseDateFromMatch(fullPathDateMatch);
					if (date) {
						SummarDebug.log(2, `Extracted recording date from full path: ${date.toISOString().split('T')[0]}`);
						return date;
					}
				}
			}
			
			// 1. í´ë” ê²½ë¡œì—ì„œ ë‚ ì§œ ì¶”ì¶œ ì‹œë„
			const folderDateMatch = folderPath.match(/(\d{4})-(\d{2})-(\d{2})|(\d{4})(\d{2})(\d{2})|(\d{4})\.(\d{2})\.(\d{2})|(\d{2})(\d{2})(\d{2})/);
			if (folderDateMatch) {
				const date = this.parseDateFromMatch(folderDateMatch);
				if (date) {
					SummarDebug.log(2, `Extracted recording date from folder path: ${date.toISOString().split('T')[0]}`);
					return date;
				}
			}

			// 2. íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ ì‹œë„
			for (const fileInfo of filesToSave) {
				const fileName = fileInfo.fileName;
				const fileNameDateMatch = fileName.match(/(\d{4})-(\d{2})-(\d{2})|(\d{4})(\d{2})(\d{2})|(\d{2})(\d{2})(\d{2})/);
				if (fileNameDateMatch) {
					const date = this.parseDateFromMatch(fileNameDateMatch);
					if (date) {
						SummarDebug.log(2, `Extracted recording date from file name: ${date.toISOString().split('T')[0]}`);
						return date;
					}
				}
			}

			// 3. íŒŒì¼ ìˆ˜ì • ì‹œê°„ì„ ì‚¬ìš© (ìµœí›„ì˜ ìˆ˜ë‹¨)
			if (filesToSave.length > 0) {
				const file = filesToSave[0].file;
				if (file.lastModified) {
					const date = new Date(file.lastModified);
					SummarDebug.log(2, `Using file modification date: ${date.toISOString().split('T')[0]}`);
					return date;
				}
			}

			SummarDebug.log(2, `Could not extract recording date from path: ${folderPath}`);
			return undefined;
		} catch (error) {
			SummarDebug.log(2, `Error extracting recording date:`, error);
			return undefined;
		}
	}
	
	/**
	 * ì •ê·œì‹ ë§¤ì¹˜ ê²°ê³¼ì—ì„œ ë‚ ì§œë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
	 */
	private parseDateFromMatch(match: RegExpMatchArray): Date | null {
		let year: number | undefined, month: number | undefined, day: number | undefined;
		
		if (match[1]) { // YYYY-MM-DD
			year = parseInt(match[1], 10);
			month = parseInt(match[2], 10) - 1;
			day = parseInt(match[3], 10);
		} else if (match[4]) { // YYYYMMDD
			year = parseInt(match[4], 10);
			month = parseInt(match[5], 10) - 1;
			day = parseInt(match[6], 10);
		} else if (match[7]) { // YYYY.MM.DD
			year = parseInt(match[7], 10);
			month = parseInt(match[8], 10) - 1;
			day = parseInt(match[9], 10);
		} else if (match[10]) { // YYMMDD (2ìë¦¬ ë…„ë„)
			const shortYear = parseInt(match[10], 10);
			// 2ìë¦¬ ë…„ë„ë¥¼ 4ìë¦¬ë¡œ ë³€í™˜ (20ë…„ëŒ€ëŠ” 2020ë…„ëŒ€, ê·¸ ì™¸ëŠ” 19ë…„ëŒ€ë¡œ ê°€ì •)
			year = shortYear >= 0 && shortYear <= 30 ? 2000 + shortYear : 1900 + shortYear;
			month = parseInt(match[11], 10) - 1;
			day = parseInt(match[12], 10);
		}
		
		if (year !== undefined && month !== undefined && day !== undefined) {
			const date = new Date(year, month, day);
			if (date.getFullYear() === year && date.getMonth() === month && date.getDate() === day) {
				return date;
			}
		}
		
		return null;
	}
}

// Helper functions
function isAudioFile(file: File): boolean {
	const audioExtensions = ['.mp3', '.wav', '.webm', '.ogg', '.m4a'];
	const fileName = file.name.toLowerCase();
	return audioExtensions.some(ext => fileName.endsWith(ext)) || file.type.startsWith('audio/');
}

async function getAudioDurationFromBlob(blob: Blob, fileName: string): Promise<number> {
  return new Promise((resolve, reject) => {
    const audio = new Audio();
    audio.preload = "metadata";

    audio.onloadedmetadata = () => {
		if (audio.duration === Infinity || isNaN(audio.duration)) {
			const match = fileName.match(/summar_audio_[^_]+_(\d+)ms\./);
			if (match && match[1]) {
				resolve(parseInt(match[1], 10)/1000); // milliseconds to seconds
			} else {
				resolve(0); // fallback to 0 if duration cannot be determined
			}
			return;
		}
		else {
			resolve(audio.duration); // duration in seconds
		}
    };
    audio.onerror = (e) => reject("Failed to load audio metadata");
    audio.src = URL.createObjectURL(blob);
  });
}